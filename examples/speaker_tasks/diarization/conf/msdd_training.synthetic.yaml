name: &name "MultiscaleDiarDecoder"
sample_rate: &sample_rate 16000
repeat: &rep 2
dropout: &drop 0.5
separable: &separable True
num_workers: &num_workers 20
batch_size: &global_bs 15

diarizer: &diarizer
  manifest_filepath: null
  out_dir: null
  oracle_vad: True # If True, uses RTTM files provided in manifest file to get speech activity (VAD) timestamps
  collar: 0.25 # Collar value for scoring
  ignore_overlap: True # Consider or ignore overlap segments while scoring

  vad:
    model_path: null # .nemo local model path or pretrained model name or none
    external_vad_manifest: null # This option is provided to use external vad and provide its speech activity labels for speaker embeddings extraction. Only one of model_path or external_vad_manifest should be set

    parameters: # Tuned parameter for CH109 (using the 11 multi-speaker sessions as dev set)
      window_length_in_sec: 0.15  # Window length in sec for VAD context input
      shift_length_in_sec: 0.01 # Shift length in sec for generate frame level VAD prediction
      smoothing: "median" # False or type of smoothing method (eg: median)
      overlap: 0.875 # Overlap ratio for overlapped mean/median smoothing filter
      onset: 0.4 # Onset threshold for detecting the beginning and end of a speech
      offset: 0.7 # Offset threshold for detecting the end of a speech
      pad_onset: 0.05 # Adding durations before each speech segment
      pad_offset: -0.1 # Adding durations after each speech segment
      min_duration_on: 0.2 # Threshold for small non_speech deletion
      min_duration_off: 0.2 # Threshold for short speech segment deletion
      filter_speech_first: True

  speaker_embeddings:
    model_path: null  # .nemo local model path or pretrained model name (titanet_large, ecapa_tdnn or speakerverification_speakernet)
    parameters:
      window_length_in_sec: [3.0, 2.5, 2.0, 1.5, 1.0, 0.5]
      shift_length_in_sec: [1.5, 1.25, 1.0, 0.75, 0.5, 0.25]
      multiscale_weights: [1,1,1,1,1,1] # weight for each scale. should be null (for single scale) or a list matched with window/shift scale count. ex) [0.33,0.33,0.33]
      save_embeddings: True # Save embeddings as pickle file for each audio input.

  clustering:
    parameters:
      oracle_num_speakers: True  # If True, use num of speakers value provided in manifest file.
      max_num_speakers: 2 # Max number of speakers for each recording. If oracle num speakers is passed, this value is ignored.
      enhanced_count_thres: 80 # If the number of segments is lower than this number, enhanced speaker counting is activated.
      max_rp_threshold: 0.15 # Determines the range of p-value search: 0 < p <= max_rp_threshold.
      sparse_search_volume: 30 # The higher the number, the more values will be examined with more time.

msdd_model:
  base:
    name: *name
    sample_rate: *sample_rate
    repeat: *rep
    dropout: *drop
    separable: *separable
    num_workers: *num_workers
    batch_size: *global_bs
    diarizer: *diarizer
    soft_label_thres: &soft_label_thres 0.5
  max_num_of_spks: &max_num_of_spks 2
  scale_n: &scale_n
  subsample_rate: &subsample_rate 1
  split_length: 30
  end_to_end_train: False
  emb_batch_size: 0
  use_longest_scale_clus_avg_emb: True
  interpolate_finest_scale: True

  train_ds:
    manifest_filepath: ???
    emb_dir: ???
    sample_rate: 16000
    num_spks: *max_num_of_spks
    soft_label_thres: *soft_label_thres
    labels: null
    batch_size: 15
    emb_batch_size: 0
    shuffle: True
    synthetic: True #whether to generate synthetic data online

  data_simulator:
    manifest_path: null # Manifest file with paths to librispeech audio files

    # alignment_type: end # input alignment format (start, end, or tuple alignments in (start,end) pairs)
    enforce_num_speakers: false # enforce that all requested speakers are present in the output wav file
    sr: 16000 # sampling rate of the audio files
    random_seed: 42

    session_config:
      num_speakers: 4 # number of unique speakers per diarization session
      num_sessions: 5 # number of sessions
      session_length: 300 # length of each diarization session (seconds)

    session_params:
      sentence_length_params: # k,p values for negative_binomial distribution
      - 0.4
      - 0.05
      dominance_var: 0.11 # variance in speaker dominance
      min_dominance: 0.05 # minimum percentage of speaking time per speaker
      turn_prob: 0.875 # probability of switching speakers
      mean_overlap: 0.19 # mean proportion of overlap to speaking time
      mean_silence: 0.15 # mean proportion of silence to speaking time
      overlap_prob: 0.5 # proportion of overlap occurences versus silence between utterances
      window_type: hamming # type of windowing used when segmenting utterances (hamming, hann, cosine)
      window_size: 0.1 # length of window at end of segmented utterance (seconds)
      normalization: equal # normalizing speakers (equal - same volume per speaker, var - variable volume per speaker)
      normalization_var: 0.1 # variance in speaker volume

    outputs:
      output_dir: null # output directory
      output_filename: diarization_session # output filename for the wav and rttm files
      overwrite_output: true
      output_files: rjctl # which files to output (r - rttm, j - json, c - ctm, t - text, l - list)

    segment_manifest:
      window: 0.5
      shift: 0.25
      step_count: 50
      deci: 3

    rir_generation: #whether to generate synthetic RIR
      use_rir: false
      #parameters match those used by https://github.com/DavidDiazGuerra/gpuRIR
      room_config:
        room_sz: # size of the shoebox room environment
        - 3
        - 3
        - 2.5
        pos_src: # positions of the speakers in the simulated room environment
        - - 0.6
          - 1.1
          - 0.5
        - - 1
          - 2
          - 0.5
        - - 0.4
          - 1.1
          - 0.5
        - - 1
          - 2.1
          - 0.5
      mic_config:
        num_channels: 1 # number of output audio channels
        pos_rcv: # microphone positions in the simulated room environment
        - - 0.5
          - 1
          - 0.5
        orV_rcv: null # microphone orientations (needed for non-omnidirectional microphones)
        mic_pattern: omni # microphone type (eg. omnidirectional)
      absorbtion_params:
        abs_weights: # absorption coefficient ratios for each surface
        - 0.9
        - 0.9
        - 0.9
        - 0.9
        - 0.9
        - 0.9
        T60: 0.1 # room reverberation time
        att_diff: 15.0 # starting attenuation (if this is different than att_max, the diffuse reverberation model is used)
        att_max: 60.0 # end attenuation

  validation_ds:
    manifest_filepath: ???
    emb_dir: ???
    sample_rate: 16000
    num_spks: *max_num_of_spks
    soft_label_thres: *soft_label_thres
    labels: null
    batch_size: 15
    emb_batch_size: 0
    shuffle: False
    synthetic: False

  preprocessor:
    _target_: nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor
    normalize: "per_feature"
    window_size: 0.025
    sample_rate: *sample_rate
    window_stride: 0.01
    window: "hann"
    features: &n_mels 80
    n_fft: 512
    frame_splicing: 1
    dither: 0.00001

  msdd_module:
    _target_: nemo.collections.asr.modules.msdd_diarizer.MSDD_module
    num_spks: *max_num_of_spks
    hidden_size: 256
    num_lstm_layers: 2
    dropout_rate: 0.5
    cnn_output_ch: 16
    conv_repeat: 1
    emb_sizes: 192
    scale_n: *scale_n
    weighting_scheme: 'conv_scale_weight'
    use_cos_sim_input: True

  loss:
    scale: 30
    margin: 0.2

  optim:
    name: adam
    lr: .001
    weight_decay: 0.001

    sched:
      name: CosineAnnealing
      min_lr: 0.00001

trainer:
  gpus: 1 # number of gpus
  max_epochs: 200
  max_steps: -1 # computed at runtime if not set
  num_nodes: 1
  strategy: ddp
  accumulate_grad_batches: 1
  deterministic: True
  enable_checkpointing: False
  logger: False
  log_every_n_steps: 1  # Interval of logging.
  val_check_interval: 1.0  # Set to 0.25 to check 4 times per epoch, or an int for number of iterations
  reload_dataloaders_every_n_epochs: 1

exp_manager:
  exp_dir: null
  name: *name
  create_tensorboard_logger: True
  create_checkpoint_callback: True
  create_wandb_logger: False
  checkpoint_callback_params:
    monitor: "val_loss"
    mode: "min"
    save_top_k: 15
    every_n_epochs: 1
  wandb_logger_kwargs:
    name: null
    project: null
